# Title  
Classification of Solar Radio Spectrum Based on Swin Transformer  

# Author  
Jian Chen et al.  

# Background  
Solar radio observation is crucial for space weather early warning and solar physics research, particularly in real-time classification of solar radio spectrums to detect solar radio bursts. Traditional methods often involve convolutional neural networks (CNNs), which are resource-intensive and have high parameter counts. The Swin transformer incorporates the benefits of CNNs, such as localization and translation invariance, while significantly improving classification accuracy and reducing computational resources.  

# Motivation  
The limitations of CNNs, including high computational demands and parameter counts, necessitate a more efficient approach. This paper introduces the Swin transformer combined with transfer learning to classify solar radio spectrums more efficiently. The method leverages pretrained model parameters, freezes the Swin transformer's hidden layer weights, and trains the fully connected layer on the target dataset, addressing the challenge of limited solar radio burst samples.  

# Methodology  
The dataset, sourced from the Chinese Academy of Sciences' solar broadband spectrometer (SBRS), includes 4408 solar radio spectrums categorized as burst, nonburst, and calibration. Preprocessing involves channel normalization to reduce noise from internal and external interference. The normalization adjusts pixel values using the formula:  
\[
\mathrm{g}(x, y)=f(x, y)-\frac{1}{n} \sum_{x=0}^{n} f(x, y)+\frac{1}{n m} \sum_{x=0}^{m} \sum_{y=0}^{n} f(x, y)
\]  
where \(m\) and \(n\) are pixel counts on the x and y axes. Grayscale images are converted to pseudocolor via bilinear interpolation, with target pixel \(g(x, y)\) calculated from neighboring pixels using:  
\[
g(x, y)=a+b+c+d
\]  
where  
\[
\begin{gathered}
a=(1-u)(1-v) f(i, j), \quad b=(1-u) v f(i, j+1), \\
c=u(1-v) f(i+1, j), \quad d=u v f(i+1, j+1).
\end{gathered}
\]  
The Swin transformer processes \(h \times w \times 3\) inputs into nonoverlapping \(4 \times 4\) patches, employing window-based self-attention (WMSA) to reduce computational complexity from \(O\left(n^{2}\right)\) to \(O(n)\). Transfer learning is applied by freezing the Swin transformer's hidden layer weights and training the fully connected layer on the target dataset.  

# Results  
The Swin transformer achieved a 100\% true positive rate (TPR) and 0\% false positive rate (FPR) across all categories (burst, nonburst, calibration). It reduced model parameters by 80\% (from 139,357,544 in VGG16 to 27,550,473) and training time significantly. Compared to the vision transformer, parameters decreased by 60\% (from 85,800,963 to 27,550,473). The model converged stably, with loss values reaching 0 by the third training round. It outperformed CGRU, CNN, multimodel, DBN, and PCA+SVM, achieving the highest TPR and lowest FPR.  

# Interpretation  
The Swin transformerâ€™s success is attributed to its self-attentive mechanism, which enhances global feature extraction and improves generalization. Its hierarchical structure, inspired by CNNs, allows gradual perceptual domain extension from local to global features. The integration of transfer learning mitigates data scarcity by leveraging pretrained parameters, while the reduced parameter count and computational complexity enhance efficiency.  

# Implication  
This method advances the automatic processing of solar radio spectrums, enabling more effective space weather monitoring and solar physics research. Its reduced computational demands and high accuracy make it suitable for real-time applications. The approach provides a robust framework for astronomical image classification, demonstrating broader potential for analyzing complex datasets in astrophysics.