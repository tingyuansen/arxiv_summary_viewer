# Title  
Multi-fidelity emulator for large-scale 21 cm lightcone images: a few-shot transfer learning approach with generative adversarial network  

# Author  
Kangning Diao et al.  

# Background  
Machine learning emulators, particularly generative adversarial networks (GANs), provide a computationally efficient alternative to large-scale numerical simulations for generating mock data from upcoming surveys. However, as simulations scale to hundreds of megaparsecs, high-fidelity emulators become prohibitively expensive. Traditional methods face challenges in balancing computational costs with the need for accuracy in emulating large-scale astrophysical structures.  

# Motivation  
The need to address the prohibitive computational costs of high-fidelity emulators for large-scale 21 cm lightcone images from the epoch of reionization (EoR) motivates this work. Existing approaches require extensive computational resources, making them impractical for generating large datasets. A cost-effective method is needed to maintain precision while reducing resource demands.  

# Methodology  
The paper introduces a multi-fidelity emulation technique using few-shot transfer learning with GANs. A GAN is first trained on 120,000 small-scale images (resolution \((64,64,512)\), comoving length \((128,128,1024) \mathrm{Mpc}\)) generated via 21CMFAST simulations, then fine-tuned on 320 large-scale images (resolution \((256,256,512)\), comoving length \((512,512,1024) \mathrm{Mpc}\)). The modified StyleGAN2 architecture includes a mapping network for astrophysical parameters (\(\zeta\), \(T_{\text{vir}}\)) and a synthesis network with noise injection. Regularization techniques, such as \(r_1\) loss and path-length loss, ensure stability. Cross-domain correspondence (CDC) loss, calculated via cosine similarity and KL divergence, preserves diversity. Training involves two steps: initial small-scale training (40,000 iterations, four GPUs) and large-scale transfer learning (2,800 iterations, two GPUs). The discriminator uses ResNet blocks and a two-layer MLP to classify images. Test sets are sampled using Latin Hypercube Sampling, with parameters \((\log_{10} \zeta, \log_{10} T_{\text{vir}})\) covering five combinations.  

# Results  
The small-scale GAN achieves subpercent relative error in global \(T_b\) signals, <20\% error in 2D power spectrum (PS), and <10\% error in scattering transform (ST) coefficients. The large-scale GAN, trained via transfer learning, achieves <5\% error in \(T_b\) signals for most cases, <10\% PS error on small scales (\(k > 0.02 \mathrm{Mpc}^{-1}\)), and <20\% ST errors. Visual inspections confirm elimination of concatenating boundaries and accurate structural reproduction. Pixel-level and feature-level variance tests indicate minimal mode collapse, except for slight issues at large scales for \(\left(\log _{10} \zeta=2.05, \log _{10} T_{\text{vir}}=4.5\right)\). Computational costs are reduced by one to two orders of magnitude (11,400 vs. 150,000–900,000 CPU core hours).  

# Interpretation  
The higher errors on very large scales (\(k \lesssim 0.02 \mathrm{Mpc}^{-1}\)) in the large-scale GAN are attributed to limited training data. The CDC loss effectively preserves diversity in generated images, as evidenced by variance tests. Transfer learning leverages small-scale simulations to capture small-scale features, while fine-tuning adapts the model to large-scale structures with minimal data. The computational savings arise from reusing pre-trained small-scale models, avoiding full retraining.  

# Implication  
This multi-fidelity approach enables cost-effective emulation of high-fidelity 21 cm lightcone images, saving 90–99\% of computational resources. It is applicable to other astrophysical domains with correlated datasets, such as low- vs. high-resolution simulations or semi-numerical vs. full-numerical models. The method supports future large-scale surveys and opens avenues for exploring alternative generative models like normalizing flows or variational autoencoders.