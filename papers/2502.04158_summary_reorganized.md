# Title  
Diffusion-based mass map reconstruction from weak lensing data  

# Author  
Supranta S. Boruah et al.  

# Background  
Weak gravitational lensing probes the underlying matter distribution by distorting galaxy shapes, with the shear field \(\gamma\) linked to the convergence field \(\kappa\). The convergence is expressed as \(\kappa(\boldsymbol{\theta}) = \int_{0}^{\chi_{\mathrm{H}}} d\chi g(\chi)\delta(\chi\boldsymbol{\theta}, \chi)\), where \(g(\chi)\) is the lensing efficiency. Traditional mass mapping methods, such as Kaiser-Squires (KS) inversion and Wiener filtering, rely on Gaussian priors, which are insufficient for late-time convergence fields due to gravitational nonlinearity. Log-normal priors and Generative Point Transformed Gaussian (GPTG) transforms offer improvements but remain limited. Generative models like GANs and normalizing flows have been explored, but diffusion models present a promising alternative for learning convergence field distributions.  

# Motivation  
Stage IV cosmological surveys (Euclid, LSST, Roman Space Telescope) require advanced methods to analyze high-quality weak lensing data. Traditional 2-point statistics miss non-Gaussian cosmological information, necessitating field-level inference (FLI) and deep learning approaches. Fast, accurate generative models are critical for applications like cluster detection, covariance estimation, and extracting non-Gaussian features. Current methods face scalability and bias challenges, motivating the development of diffusion-based frameworks to address these limitations.  

# Methodology  
A diffusion model is developed for simulating weak lensing maps and reconstructing mass maps via Diffusion Posterior Sampling (DPS). The forward stochastic differential equation (SDE) \(\mathrm{d} \boldsymbol{x}=f(\boldsymbol{x}, t) \mathrm{d} t+g(t) \mathrm{d} \boldsymbol{w}\) adds noise to convergence maps, while the reverse process \(\mathrm{d} \boldsymbol{x}=\left[f(\boldsymbol{x}, t)-g^{2}(t) \nabla_{\boldsymbol{x}} \log p_{t}(\boldsymbol{x})\right] \mathrm{d} t+g(t) \mathrm{d} \boldsymbol{w}\) denoises using a score network \(\boldsymbol{s}_{\boldsymbol{\theta}}(\boldsymbol{x}, t)\). The model is trained on convergence maps from the MassiveNuS simulation suite at redshifts \(z=0.5, 1.0, 1.5\), regridded to \(256 \times 256\) pixels. Noisy mock shear data with LSST-Y10-like shape noise are generated for posterior sampling. To mitigate bias in standard DPS, the likelihood term is down-weighted at early sampling steps using \(A(t)=\operatorname{Sigmoid}\left[\frac{\bar{t}-t}{\sigma_{t}}\right]\) with \(\bar{t}=500\) and \(\sigma_{t}=20\). A UNet with 35 million parameters approximates the score function, trained via loss \(L(\boldsymbol{\theta})=\mathbb{E}\left[\left\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_{\boldsymbol{\theta}}\left(\sqrt{\bar{\alpha}_{t}} \boldsymbol{x}_{0}+\sqrt{1-\bar{\alpha}_{t} \boldsymbol{\epsilon}}, t\right)\right\|^{2}\right]\).  

# Results  
The diffusion model generates convergence maps with \(<1\%\) power spectrum bias and accurate non-Gaussian statistics, validated via scattering transforms \(S_1(j_1) = \langle|\kappa * \psi(j_1)|\rangle\) and \(S_2(j_1, j_2) = \langle||\kappa * \psi(j_1)| * \psi(j_2)|\rangle\). Posterior sampling reconstructs mass maps with \(\sim 50\%\) improvement in RMSE and Pearson correlation \(\rho_{c}\) over KS inversion, particularly at low redshifts. Signal-to-noise ratio (SNR) contours detect peaks and voids, while pixel-wise uncertainty quantification reveals spatially correlated errors. The model reproduces covariance matrices for cosmological inference and outperforms Gaussian/lognormal prior-based methods in small-scale fidelity.  

# Interpretation  
The diffusion model captures the joint distribution of non-Gaussian statistics, enabling accurate covariance estimation and unbiased mass map reconstruction. Down-weighting the likelihood term in DPS reduces early-time sampling bias, validated by alignment of posterior maps (via 1-point PDF, peak counts, and void counts) with true convergence fields. The method’s scalability and computational efficiency (\(\mathcal{O}(50\) seconds per sample on a V100 GPU) address limitations of traditional Bayesian and machine learning approaches, which struggle with multimodal posteriors and high-resolution data.  

# Implication  
The framework streamlines weak lensing analysis by unifying simulation generation and inverse problem solving. It enables rapid production of simulation-quality maps (\(\mathcal{O}(10\) seconds on GPU), aiding covariance estimation and large-scale structure studies. Applications include detecting filaments, voids, and clusters from noisy data, enhancing signal-to-noise for less massive structures. Future extensions could integrate the model into field-level cosmological inference, improving constraints on parameters like \(S_8\) and \(\Omega_m\). The method’s open-source implementation facilitates adoption in upcoming surveys, advancing non-Gaussian cosmology research.